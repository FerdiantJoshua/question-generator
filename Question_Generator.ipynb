{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch import optim\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logger Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "c_handler = logging.StreamHandler(sys.stdout)\n",
    "# c_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "c_format = logging.Formatter(f'%(levelname)-8s: %(message)s')\n",
    "c_handler.setFormatter(c_format)\n",
    "\n",
    "for handler in logger.handlers:\n",
    "    logger.removeHandler(handler)\n",
    "logger.addHandler(c_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO    : test\n"
     ]
    }
   ],
   "source": [
    "logger.info('test')\n",
    "logger.debug('aku adalah anak gembala')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 2)\n",
      "                                           title  \\\n",
      "0                                        Beyonce   \n",
      "1                                Frédéric Chopin   \n",
      "2    Hubungan Tiongkok-Tibet selama dinasti Ming   \n",
      "3                                           IPod   \n",
      "4         The Legend of Zelda: Twilight Princess   \n",
      "..                                           ...   \n",
      "437                                      Infeksi   \n",
      "438                                      Berburu   \n",
      "439                                    Kathmandu   \n",
      "440                               Infark miokard   \n",
      "441                                      Masalah   \n",
      "\n",
      "                                            paragraphs  \n",
      "0    [{'qas': [{'question': 'Kapan Beyonce mulai me...  \n",
      "1    [{'qas': [{'question': 'Bagaimana kewarganegar...  \n",
      "2    [{'qas': [{'question': 'Siapakah Wang Jiawei d...  \n",
      "3    [{'qas': [{'question': 'Perusahaan mana yang m...  \n",
      "4    [{'qas': [{'question': 'Apa kategori game Lege...  \n",
      "..                                                 ...  \n",
      "437  [{'qas': [{'question': 'Dari sejumlah besar mi...  \n",
      "438  [{'qas': [{'question': 'Apa praktik membunuh a...  \n",
      "439  [{'qas': [{'question': 'Negara mana Kathmandu ...  \n",
      "440  [{'qas': [{'plausible_answers': [{'text': 'Inf...  \n",
      "441  [{'qas': [{'plausible_answers': [{'text': 'mat...  \n",
      "\n",
      "[442 rows x 2 columns]\n",
      "(442, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Beyoncé', 'paragraphs': [{'qas': [{...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Frédéric_Chopin', 'paragraphs': [{'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'Sino-Tibetan_relations_during_the_M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'IPod', 'paragraphs': [{'qas': [{'qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>{'title': 'The_Legend_of_Zelda:_Twilight_Princ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  version                                               data\n",
       "0    v2.0  {'title': 'Beyoncé', 'paragraphs': [{'qas': [{...\n",
       "1    v2.0  {'title': 'Frédéric_Chopin', 'paragraphs': [{'...\n",
       "2    v2.0  {'title': 'Sino-Tibetan_relations_during_the_M...\n",
       "3    v2.0  {'title': 'IPod', 'paragraphs': [{'qas': [{'qu...\n",
       "4    v2.0  {'title': 'The_Legend_of_Zelda:_Twilight_Princ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SQUAD_DATASET_PATH = 'Datasets/SQuAD/v2.0/train-v2.0-translated.json'\n",
    "\n",
    "df_squad = pd.read_json(SQUAD_DATASET_PATH)\n",
    "df_squad = df_squad\n",
    "print(df_squad.shape)\n",
    "print(df_squad)\n",
    "\n",
    "df_squad_original = pd.read_json('Datasets/SQuAD/v2.0/train-v2.0.json')\n",
    "print(df_squad_original.shape)\n",
    "df_squad_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gothic architecture is a style of architecture that flourished during the high and late medieval period. It evolved from Romanesque architecture and was succeeded by Renaissance architecture. Originating in 12th-century France and lasting into the 16th century, Gothic architecture was known during the period as Opus Francigenum (\"French work\") with the term Gothic first appearing during the later part of the Renaissance. Its characteristics include the pointed arch, the ribbed vault and the flying buttress. Gothic architecture is most familiar as the architecture of many of the great cathedrals, abbeys and churches of Europe. It is also the architecture of many castles, palaces, town halls, guild halls, universities and to a less prominent extent, private dwellings, such as dorms and rooms.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is one time period in which Gothic architecture flourished?',\n",
       "  'id': '57268fad5951b619008f769b',\n",
       "  'answers': [{'text': 'late medieval period', 'answer_start': 83}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'What style of architecture did Gothic architecture evolve from?',\n",
       "  'id': '57268fad5951b619008f769c',\n",
       "  'answers': [{'text': 'Romanesque architecture', 'answer_start': 121}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'What style of architecture came after the Gothic style?',\n",
       "  'id': '57268fad5951b619008f769d',\n",
       "  'answers': [{'text': 'Renaissance architecture', 'answer_start': 166}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'Where did the Gothic architecture style originate?',\n",
       "  'id': '57268fad5951b619008f769e',\n",
       "  'answers': [{'text': 'France', 'answer_start': 220}],\n",
       "  'is_impossible': False},\n",
       " {'question': 'Gothic architecture is known for being commonly used in cathedrals and churches, what is one example of a lesser known type of structure in which Gothic architecture has been used?',\n",
       "  'id': '57268fad5951b619008f769f',\n",
       "  'answers': [{'text': 'private dwellings, such as dorms and rooms',\n",
       "    'answer_start': 758}],\n",
       "  'is_impossible': False},\n",
       " {'plausible_answers': [{'text': 'late medieval period', 'answer_start': 83}],\n",
       "  'question': 'What is one time period in which Gothic architecture was not allowed?',\n",
       "  'id': '5ad0bf10645df0001a2d0194',\n",
       "  'answers': [],\n",
       "  'is_impossible': True},\n",
       " {'plausible_answers': [{'text': 'Romanesque architecture',\n",
       "    'answer_start': 121}],\n",
       "  'question': 'What style of architecture did Gothic architecture devolve from?',\n",
       "  'id': '5ad0bf10645df0001a2d0195',\n",
       "  'answers': [],\n",
       "  'is_impossible': True},\n",
       " {'plausible_answers': [{'text': 'Renaissance architecture',\n",
       "    'answer_start': 166}],\n",
       "  'question': 'What style of architecture came along with the Gothic style?',\n",
       "  'id': '5ad0bf10645df0001a2d0196',\n",
       "  'answers': [],\n",
       "  'is_impossible': True},\n",
       " {'plausible_answers': [{'text': 'France', 'answer_start': 220}],\n",
       "  'question': 'Where did the Gothic architecture style fail originally?',\n",
       "  'id': '5ad0bf10645df0001a2d0197',\n",
       "  'answers': [],\n",
       "  'is_impossible': True},\n",
       " {'plausible_answers': [{'text': 'Gothic architecture', 'answer_start': 0}],\n",
       "  'question': 'What style of architecture no longer exists for castles?',\n",
       "  'id': '5ad0bf10645df0001a2d0198',\n",
       "  'answers': [],\n",
       "  'is_impossible': True}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_squad_original['title'] = df_squad_original['data'].apply(lambda x: x.get('title'))\n",
    "df_squad_original['paragraphs'] = df_squad_original['data'].apply(lambda x: x.get('paragraphs'))\n",
    "df_squad_original.drop(columns=['data'], inplace=True)\n",
    "\n",
    "print(df_squad_original.iloc[220]['paragraphs'][0]['context'])\n",
    "df_squad_original.iloc[220]['paragraphs'][0]['qas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{m}m {s}s'\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return f'{asMinutes(s)} (- {asMinutes(rs)})'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oktober\n",
      "Oktober\n",
      "\n",
      "Perancis\n",
      "Perancis\n",
      "\n",
      "alasan Istana\n",
      "alasan Istana\n",
      "\n",
      "seruling dan biola\n",
      "seruling dan biola\n",
      "\n",
      "penyakit\n",
      "penyakit\n",
      "\n",
      "Oktober 1810\n",
      "Oktober 1810\n",
      "\n",
      "Lyceum Warsawa\n",
      "Lyceum Warsawa\n",
      "\n",
      "seruling dan biola\n",
      "seruling dan biola\n",
      "\n",
      "rencana\n",
      "piano\n",
      "\n",
      "enam bulan\n",
      "enam bulan\n",
      "\n",
      "Perancis\n",
      "Perancis\n",
      "\n",
      "seruling dan biola\n",
      "seruling dan biola\n",
      "\n",
      "rencana\n",
      "piano\n",
      "\n",
      "Istana Saxon.\n",
      "Istana Saxon.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # for topic_idx in df_squad.iloc[0]['paragraphs']:\n",
    "# for question in df_squad.iloc[1]['paragraphs'][6]['qas']:\n",
    "#     answers = question['answers'][0]\n",
    "#     print(answers['text'])\n",
    "# #     # 0,0\n",
    "# #     if answers['text'] == 'Berbahaya dalam Cinta':\n",
    "# #         answers['text'] = 'Dangerously in Love'\n",
    "# #     elif answers['text'] == 'bernyanyi dan menari':\n",
    "# #         answers['text'] = 'menyanyi dan menari'\n",
    "# #     # 0,1\n",
    "# #     if answers['text'] == 'Beyonce':\n",
    "# #         answers['text'] = 'Beyoncé '\n",
    "# #     # 0,3\n",
    "# #     if answers['text'] == 'Metodis':\n",
    "# #         answers['text'] = 'Metodhis'\n",
    "# #     elif answers['text'] == 'Amerika Afrika':\n",
    "# #         answers['text'] = 'Afrika-Amerika'\n",
    "# #     # 1,0\n",
    "#     if answers['text'] == 'hanya perlahan':\n",
    "#         answers['text'] = 'piano solo'\n",
    "# #     # 1,3\n",
    "#     if answers['text'] == 'rencana':\n",
    "#         answers['text'] = 'piano'\n",
    "#     print(answers['text'])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "FIND_STRING_APPROX_ATTEMPT_LIMIT = 3\n",
    "SHORT_ANSWER_THRESHOLD = 2\n",
    "SENTENCE_SIMILARITY_THRESHOLD = 0.5\n",
    "WORD_SIMILARITY_THRESHOLD = 80\n",
    "NOT_FOUND_VALUE = (-1, -1)\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    filtered = [w.translate(table) for w in text.split()]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "def find_word_in_list_approx(list_word, word, start_search_idx=0):\n",
    "    found = False\n",
    "    i = start_search_idx\n",
    "    while i < len(list_word) and not found:\n",
    "        found = fuzz.token_set_ratio(list_word[i], word) > WORD_SIMILARITY_THRESHOLD\n",
    "        i += 1\n",
    "    if found:\n",
    "        return i-1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def find_string_approx(context, answer, logger=logger):\n",
    "    context_words = context.split()\n",
    "    answer_words = answer.split()\n",
    "    context_words_length = len(context_words)\n",
    "    answer_words_length = len(answer_words)\n",
    "    \n",
    "    # string.find only used for numeric, else use fuzzywuzzy\n",
    "    if answer.strip().isnumeric():\n",
    "        char_pos_start = context.find(answer)\n",
    "        char_pos_end = char_pos_start + len(answer)\n",
    "        return (char_pos_start, char_pos_end)\n",
    "        \n",
    "    found = False        \n",
    "    attempt = 0\n",
    "    \n",
    "    i_initial = -1\n",
    "    j_initial = 0    \n",
    "    i_start = i_initial\n",
    "    j_start = j_initial\n",
    "    while attempt < FIND_STRING_APPROX_ATTEMPT_LIMIT and not found:\n",
    "        if attempt > 0: logger.debug(f'Trying another starting word. Attempt {attempt+1}..')\n",
    "        while (i_start == i_initial or i_start == -1) and j_start < answer_words_length:\n",
    "            i_start = find_word_in_list_approx(context_words, answer_words[j_start], start_search_idx=i_initial+1)\n",
    "#             logger.debug(answer_words[j_start])\n",
    "#             logger.debug(i_start)\n",
    "            if i_start == -1:\n",
    "                i_initial = -1\n",
    "                j_start += 1\n",
    "        if i_start == -1:\n",
    "            return NOT_FOUND_VALUE\n",
    "\n",
    "#         logger.debug(answer_words[j_start])\n",
    "#         logger.debug(i_start)\n",
    "        match_count = 0\n",
    "        i = i_start\n",
    "        j = j_start\n",
    "        while i < context_words_length and j < answer_words_length:\n",
    "#             logger.debug(f'{context_words[i]} vs {answer_words[j]}')\n",
    "            if fuzz.token_set_ratio(context_words[i], answer_words[j]) > WORD_SIMILARITY_THRESHOLD:\n",
    "                match_count += 1\n",
    "                i += 1\n",
    "                j += 1\n",
    "            else:\n",
    "                if j < answer_words_length-1 and fuzz.token_set_ratio(context_words[i], answer_words[j+1]) > WORD_SIMILARITY_THRESHOLD:\n",
    "                    match_count += 1\n",
    "                    i += 1\n",
    "                    j += 2\n",
    "                elif i < context_words_length-1 and fuzz.token_set_ratio(context_words[i+1], answer_words[j]) > WORD_SIMILARITY_THRESHOLD:\n",
    "                    match_count += 1\n",
    "                    i += 2\n",
    "                    j += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "                    j += 1\n",
    "                    \n",
    "        similarity = match_count / answer_words_length\n",
    "        if similarity >= SENTENCE_SIMILARITY_THRESHOLD and not (answer_words_length == 2 and similarity == 0.5): # half correct for 2 length words is considered unsimilar            \n",
    "            char_pos_start = 0\n",
    "            start_idx = i_start\n",
    "            for k in range(start_idx):\n",
    "                char_pos_start += len(context_words[k]) + 1\n",
    "                \n",
    "            char_pos_end = 0\n",
    "            end_idx = i\n",
    "            for k in range(start_idx, end_idx):\n",
    "                char_pos_end += len(context_words[k]) + 1\n",
    "            found = True\n",
    "        else:\n",
    "            attempt += 1\n",
    "            logger.debug('Not found..')\n",
    "            i_initial = i_start    \n",
    "            \n",
    "    if found:\n",
    "        logger.debug(f'start:({i_start}, {j_start}), end:({i-1}, {j-1}), ({context_words[i_start]},{answer_words[j_start]}), {match_count}/{answer_words_length}={similarity:.2f}')\n",
    "        return (char_pos_start, char_pos_start+char_pos_end-1)        \n",
    "    else:\n",
    "        logger.debug(f'({i-1},{j-1}): {match_count}/{answer_words_length}={similarity:.2f}')\n",
    "        return NOT_FOUND_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 153)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_string_approx('at, republik meskipun terdapat berbagai kepentingan dalam konflik atau dengan para pejuang, seperti Denmark-Norwegia. Republik Belanda, sekutu lama Inggris, mempertahankan kenetralannya, takut akan kemungkinan melawan Inggris dan Prusia melawan kekuatan besar Eropa, bahkan beru', 'Republik Belanda')\n",
    "find_string_approx('Buddhisme / ˈbudɪzəm / adalah agama nonthisti [catatan 1] atau filsafat (bahasa Sansekerta: धर्म dharma; Pali: धम्धम dhamma) yang mencakup berbagai tradisi, kepercayaan, dan praktik spiritual yang sebagian besar didasarkan pada ajaran yang dikaitkan dengan Buddha Gautama, umumnya dikenal sebagai Buddha (\"yang terbangun\"). Menurut tradisi Buddha, Buddha hidup dan mengajar di bagian timur anak benua India, Nepal saat ini sekitar abad ke 6 dan 4 SM. [Catatan 1] Ia diakui oleh umat Buddha sebagai guru yang terbangun atau tercerahkan yang berbagi pengalamannya dengan Buddha. wawasan untuk membantu makhluk hidup mengakhiri penderitaan mereka melalui penghapusan ketidaktahuan dan keinginan. Umat Buddha percaya bahwa ini dicapai melalui pemahaman dan persepsi langsung tentang kemunculan bergantungan dan Empat Kebenaran Mulia.', 'agama nontheistik')\n",
    "find_string_approx('a Nikaya, yang diakui oleh sebagian besar cendekiawan sebagai teks awal (lih. Baptisan bayi). Buddhisme Tibet terkadang menambahkan perlindungan keempat, dalam lama. Di Mahayana, orang yang memilih jalur bodhisattva membuat sumpah atau janji, dianggap sebagai ekspresi tertinggi dari welas asih. Di Mahayana juga, Tiga Permata dian', 'Tibet')\n",
    "find_string_approx('Koloni dan komunitas Yunani di tepi Laut Mediterania dan Laut Hitam, tetapi orang-orang Yunani selalu berpusat di laut Aegean dan Ionia, di mana bahasa Yunani telah digunakan sejak Zaman Perunggu. Hingga awal abad ke-20, orang-orang Yunani beralih ke semenanjung Yunani, pantai barat Asia Kecil, pantai Laut Hitam, Kapadokia di Anatolia tengah, Mesi', 'Koloni dan komunitas Yunani secara historis didirikan di tepi Laut Mediterania dan Laut Hitam')\n",
    "find_string_approx('ercaya bahwa invasi Dorian menyebabkan runtuhnya peradaban Mycenaean, tetapi kemungkinan serangan utama dilakukan oleh perampok pelaut (orang-orang laut) yang berlayar ke Mediterania timur sekitar tahun 1180 SM. Invasi Dorian diikuti oleh periode migrasi yang terbukti buruk, yang secara tepat disebut Abad Kegelapan Yunani, tetapi pada 800 SM lansekap Yunani Kuno dan Klasik sudah terlihat.', 'Diharapkan serangan utama dilakukan oleh perampok pelaut (masyarakat laut)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_OFFSET = 68\n",
    "RIGHT_OFFSET = 256\n",
    "\n",
    "IMPOSSIBLE_LOC = (-2, -2)\n",
    "\n",
    "def get_answer_loc_new(context, answer_text, answer_loc, logger=logger):\n",
    "    if answer_text == '':\n",
    "        return IMPOSSIBLE_LOC\n",
    "    \n",
    "    answer_text_total_words = len(answer_text.split())\n",
    "            \n",
    "    context_loc = (max(answer_loc[0]-len(answer_text)-LEFT_OFFSET, 0), min(answer_loc[0]+len(answer_text)+RIGHT_OFFSET, len(context)))\n",
    "    prepared_context = context[context_loc[0]:context_loc[1]].lower()\n",
    "    prepared_answer_text = answer_text.lower()\n",
    "\n",
    "    answer_loc_start, answer_loc_end = find_string_approx(prepared_context, prepared_answer_text, logger)\n",
    "    if answer_loc_start != -1:\n",
    "        answer_loc_new = (\n",
    "            answer_loc_start + context_loc[0],\n",
    "            answer_loc_end + context_loc[0]\n",
    "        )\n",
    "        logger.debug(f'Indonesia answer_loc_new: {answer_loc_new}')\n",
    "    else:\n",
    "        answer_loc_new = (-1, -1)\n",
    "        logger.debug(context[context_loc[0]:context_loc[1]])\n",
    "        logger.debug(f'INDONESIA ANSWER_LOC NOT FOUND: {answer_loc_new}')\n",
    "    return answer_loc_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_add_context_failures(taken_topic_idx, taken_context_idx, logger=logger):\n",
    "    qas = df_squad.iloc[taken_topic_idx]['paragraphs'][taken_context_idx]['qas']\n",
    "    context = df_squad.iloc[taken_topic_idx]['paragraphs'][taken_context_idx]['context']\n",
    "    logger.debug(f'{context}\\n')\n",
    "\n",
    "    failure_count = 0\n",
    "    i = 0\n",
    "    for question in qas:\n",
    "        logger.debug(i)\n",
    "        answers = question['answers']\n",
    "        if len(answers) == 0:\n",
    "            logger.debug(\"Impossible question. Alternating to plausible answers...\")\n",
    "            answers_key = 'plausible_answers'\n",
    "        else:\n",
    "            answers_key = 'answers'\n",
    "        answer_text = question[answers_key][0]['text']\n",
    "        answer_loc = int(question[answers_key][0]['answer_start'])\n",
    "        answer_loc = (min(answer_loc, len(context) - 1), min(answer_loc + len(answer_text), len(context)))\n",
    "        logger.debug(f'English answer_loc: {answer_loc}')\n",
    "\n",
    "        answer_loc_new = get_answer_loc_new(context, answer_text, answer_loc, logger)\n",
    "    \n",
    "        # If not found, try the original english answer. Probably GoogleTranslate had translated name entities.\n",
    "        if answer_loc_new == (-1, -1):\n",
    "            answer_text = df_squad_original.iloc[taken_topic_idx]['paragraphs'][taken_context_idx]['qas'][i][answers_key][0]['text']\n",
    "            answer_loc_new = get_answer_loc_new(context, answer_text, answer_loc, logger)\n",
    "\n",
    "        failure_count += 1 if answer_loc_new == (-1, -1) else 0\n",
    "        \n",
    "        i += 1\n",
    "#         if answer_loc_new == (-1, -1):\n",
    "        logger.debug(f'Question: {question[\"question\"]}')\n",
    "        logger.debug(f'Answer: {question[answers_key]}')\n",
    "        logger.debug(f'Located in context: {context[answer_loc_new[0]:answer_loc_new[1]]}')\n",
    "        logger.debug('')\n",
    "    logger.debug(f'Failure counts:{failure_count}')\n",
    "    df_squad.iloc[taken_topic_idx]['paragraphs'][taken_context_idx]['failure_count'] = failure_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for taken_topic_idx in range(df_squad.shape[0]):\n",
    "    logger.debug(f'Topic: {taken_topic_idx}')\n",
    "    for taken_context_idx in range(len(df_squad.iloc[taken_topic_idx]['paragraphs'])):\n",
    "        logger.debug(f'\\t{taken_context_idx}')\n",
    "        calculate_add_context_failures(taken_topic_idx, taken_context_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add failure_percentage column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "failure_percentage = [0.0 for _ in range(df_squad.shape[0])]\n",
    "total_questions = [0 for _ in range(df_squad.shape[0])]\n",
    "\n",
    "for taken_topic_idx in range(df_squad.shape[0]):\n",
    "    logger.debug(f'Topic: {taken_topic_idx}')\n",
    "    ctx_total_question = []\n",
    "    failure_list = []\n",
    "    \n",
    "    for taken_context_idx in range(len(df_squad.iloc[taken_topic_idx]['paragraphs'])):\n",
    "        logger.debug(f'\\tContext_idx: {taken_context_idx}')\n",
    "        context = df_squad.iloc[taken_topic_idx]['paragraphs'][taken_context_idx]\n",
    "        qas_total_question = len(context['qas'])\n",
    "        ctx_failure_percentage = context['failure_count']/qas_total_question\n",
    "        logger.debug(f'\\tFailures: {context[\"failure_count\"]}/{qas_total_question} = {ctx_failure_percentage * 100:.2f}%')\n",
    "        ctx_total_question.append(qas_total_question)\n",
    "        failure_list.append(ctx_failure_percentage)\n",
    "        \n",
    "    total_questions[taken_topic_idx] = sum(ctx_total_question)\n",
    "    failure_percentage[taken_topic_idx] = sum(failure_list)/len(failure_list)\n",
    "    \n",
    "df_squad['failure_percentage'] = failure_percentage\n",
    "df_squad['total_questions'] = total_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    442.000000\n",
      "mean       0.074778\n",
      "std        0.036971\n",
      "min        0.000000\n",
      "25%        0.048648\n",
      "50%        0.066257\n",
      "75%        0.094361\n",
      "max        0.258333\n",
      "Name: failure_percentage, dtype: float64\n",
      "[378, 11, 438, 413, 91, 89, 13, 171, 386, 228, 381, 48, 267, 121, 293, 75, 285, 6, 367, 174, 373, 259, 415, 185, 220, 163, 394, 59, 308, 55, 209, 40, 287, 212, 307, 421, 166, 151, 404, 236, 170, 238, 242, 346, 152, 387, 157, 316, 28, 46, 409, 116, 357, 359, 178, 78, 305, 399, 141, 145, 360, 44, 361, 68, 349, 227, 233, 1, 302, 223, 80, 292, 204, 424, 433, 379, 72, 412, 43, 81, 280, 108, 342, 291, 12, 114, 422, 160, 215, 118, 22, 315, 406, 124, 416, 321, 437, 107, 182, 269, 262, 248, 0, 398, 334, 73, 186, 34, 402, 306, 144, 229, 284, 14, 265, 92, 411, 364, 86, 390, 430, 300, 408, 191, 202, 400, 250, 356, 426, 282, 354, 24, 245, 154, 7, 213, 23, 159, 352, 281, 278, 425, 343, 61, 441, 37, 4, 255, 74, 65, 70, 235, 194, 164, 237, 335, 100, 168, 146, 329, 189, 210, 369, 261, 225, 58, 299, 304, 325, 403, 428, 97, 385, 150, 190, 161, 247, 123, 200, 301, 252, 234, 15, 330, 131, 268, 184, 383, 27, 368, 94, 90, 199, 230, 254, 172, 382, 16, 226, 77, 162, 169, 429, 156, 158, 401, 374, 380, 76, 120, 211, 53, 113, 26, 88, 427, 60, 232, 193, 231, 331, 8, 439, 341, 103, 395, 217, 388, 365, 135, 197, 419, 275, 101, 314, 396, 56, 271, 414, 391, 243, 214, 348, 179, 21, 66, 260, 393, 241, 87, 339, 134, 431, 93, 33, 17, 18, 258, 62, 127, 180, 96, 173, 338, 84, 384, 283, 42, 327, 149, 136, 221, 138, 95, 195, 256, 71, 196, 313, 410, 165, 5, 218, 435, 140, 358, 353, 207, 397, 407, 20, 188, 129, 392, 79, 347, 276, 272, 224, 375, 142, 102, 63, 326, 266, 363, 264, 177, 320, 203, 85, 322, 286, 351, 298, 279, 420, 64, 216, 110, 30, 9, 10, 25, 128, 31, 125, 253, 296, 109, 143, 32, 295, 206, 47, 187, 355, 294, 198, 323, 311, 54, 432, 153, 336, 333, 41, 362, 377, 139, 274, 310, 270, 3, 239, 119, 337, 257, 147, 2, 57, 319, 312, 122, 366, 289, 29, 277, 51, 83, 370, 104, 344, 82, 181, 371, 222, 52, 417, 309, 436, 328, 167, 317, 19, 340, 249, 38, 69, 45, 130, 175, 208, 205, 176, 36, 240, 324, 318, 345, 288, 99, 290, 440, 297, 332, 192, 418, 376, 303, 389, 49, 246, 350, 111, 423, 133, 273, 35, 405, 106, 251, 98, 263, 183, 112, 137, 132, 39, 67, 219, 117, 201, 434, 126, 155, 244, 50, 372, 105, 115, 148]\n",
      "                      title  failure_percentage  total_questions  \\\n",
      "378  Papan sirkuit tercetak            0.215397              325   \n",
      "11             Agama Buddha            0.114164              610   \n",
      "438                 Berburu            0.121072              531   \n",
      "413      Agama di Roma kuno            0.158025              405   \n",
      "91         Abad Pertengahan            0.138172              452   \n",
      "..                      ...                 ...              ...   \n",
      "50         Ras Luar Angkasa            0.017857              173   \n",
      "372   Badan Intelijen Pusat            0.037500               65   \n",
      "105           Pitch (musik)            0.058333               36   \n",
      "115                   Satwa            0.026471               79   \n",
      "148        General Electric            0.000000              158   \n",
      "\n",
      "     failed_questions  \n",
      "378         70.003968  \n",
      "11          69.639793  \n",
      "438         64.288971  \n",
      "413         64.000000  \n",
      "91          62.453763  \n",
      "..                ...  \n",
      "50           3.089286  \n",
      "372          2.437500  \n",
      "105          2.100000  \n",
      "115          2.091176  \n",
      "148          0.000000  \n",
      "\n",
      "[442 rows x 4 columns]\n",
      "Dropped: 9561.80493530305\n",
      "Total: 130319\n"
     ]
    }
   ],
   "source": [
    "# df_analysis = df_squad[df_squad.failure_percentage > 0.12].drop(columns=['paragraphs'])\n",
    "df_analysis = df_squad.drop(columns=['paragraphs'])\n",
    "print(df_analysis.failure_percentage.describe())\n",
    "df_analysis['failed_questions'] = df_analysis['failure_percentage'] * df_analysis['total_questions']\n",
    "df_analysis = df_analysis.sort_values(by=['failed_questions'], ascending=False)\n",
    "sorted_index = df_analysis.index\n",
    "print(sorted_index.tolist())\n",
    "print(df_analysis)\n",
    "print(f\"Dropped: {df_analysis['failed_questions'].sum()}\")\n",
    "print(f\"Total: {df_analysis['total_questions'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOGGER_NAME = 'file_logger'\n",
    "\n",
    "# File logger\n",
    "file_logger = logging.getLogger(FILE_LOGGER_NAME)\n",
    "file_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "f_handler = logging.FileHandler('answer_findings_log.txt', 'w', 'utf-8')\n",
    "f_format = logging.Formatter('%(message)s')\n",
    "f_handler.setFormatter(f_format)\n",
    "\n",
    "for handler in file_logger.handlers:\n",
    "    file_logger.removeHandler(handler)    \n",
    "file_logger.addHandler(f_handler)\n",
    "\n",
    "for i in range(len(sorted_index)):\n",
    "    taken_topic_idx = sorted_index[i]\n",
    "    file_logger.debug(f'Topic {taken_topic_idx}: {df_squad.iloc[taken_topic_idx][\"title\"]}')\n",
    "    file_logger.debug(f'Rank: {i}')\n",
    "    file_logger.debug(f'Failure rate: {df_analysis[\"failed_questions\"][taken_topic_idx]:.0f}/{df_analysis[\"total_questions\"][taken_topic_idx]} = {df_analysis[\"failure_percentage\"][taken_topic_idx]:.2f}%')\n",
    "    for taken_context_idx in range(len(df_squad.iloc[taken_topic_idx]['paragraphs'])):\n",
    "        calculate_add_context_failures(taken_topic_idx, taken_context_idx, file_logger)\n",
    "        file_logger.debug('---------- END OF CONTEXT ----------')\n",
    "    file_logger.debug(f'========== END OF TOPIC {taken_topic_idx} ==========\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend('agg')\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
